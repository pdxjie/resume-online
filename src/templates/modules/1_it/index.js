/**
 * @Author: 派同学
 * @Description: How
 */
const content = `::: headStart
::: start
## ikun **大数据开发工程师** **意向城市：杭州**
::: start
icon:user 男 / 2000.01.01
icon:phone 155xxxxxx06
:::
icon:email [xxxxxxxx@163.com](xxxxxxxx@163.com)
icon:gitee [gitee.com/codeleilei](https://gitee.com/codeleilei)
:::
icon:github [github.com/acmenlei](https://github.com/acmenlei)
icon:yuque [yuque.com/xiongleixin](https://www.yuque.com/xiongleixin)
::: end
:::
![个人头像](https://codeleilei.gitee.io/blog/avatar.jpg)
::: end
::: headEnd

## icon:user 教育背景 Education Background
::: start
- **清华大学 - 信息工程学院 - 计算机科学与技术**
:::
**2019-09-01 至 2023-07-01**
::: end
- GPA：4.0 / 专业Top 1

## icon:technology 专业技能 Professional Skills
- 熟悉 Java 编程基础，IO操作，集合等相关知识，了解常见的设计模式和计算机基础相关知识。
- 熟悉 Linux 基本命令，具备编写简单的 Shell 脚本的能力。
- 熟悉 MySQL 且具有编写 SQL 的能力，了解 MySQL 逻辑架构、索引、锁、事务等。
- 熟悉 HTML、CSS 并能编写符合 W3C 标准的页面布局以及熟悉 JavaScript。
- 熟悉常用数据结构如数组、连标、栈、队列、二叉树等，对递归、动态规划、常用排序算法有一定理解。
- 熟悉 Hadoop 生态的大数据存储平台的搭建与部署及相关组件（HDFS、Yarm、MapReduce 编程模型）。
- 熟练 Python 编程基础，有 PyhtonWeb、爬虫、数据分析、自动化脚本、QT 编程等经验。
- 熟悉 C++ 编程基础，有 C++ 小游戏及管理系统开发经验。

## icon:trophy 奖项荣誉 Awards & Honor
- 2021 - 2022年国家励志奖学金 / 2019 - 2020年国家奖学金
- 2020年全国高等学校计算机能力挑战赛一等奖
- 2019年 CCPC 大学生程序设计大赛江西区预赛银牌
- 2022年 “牛逼杯” xxxxxx大学信息工程学院牛逼作品大赛 一等奖

## icon:practice 实习经历 Intership Experience
- **单位名称**：xxxxxxxxx
- **实习时间**：xxxx.xx - xxxx.xx
- **实习内容**：使用 Python 语言编写的 Scrapy 框架及 requests 等第三方库，对网络上公开的数据进行爬取，并存储到 MySQL 数据库中，再利用 Java 及 Python 的数据科学库对数据进行清洗及分析等内容。

## icon:project 项目经历 Project Experience
- **项目名称**：阿里巴巴达摩院扫地项目
- **项目时间**：2022.06 - 2022.07
- **项目描述**：教别人如何扫地，如何扫好地
- **项目技术栈**：Hadoop、Sqoop、Python、Scrapy、Spark、Hive、MySQL、Flask、ECharts
- **指责描述**：进行 Hadoop 平台搭建，利用 Scrapy 爬取 QTA 酒店公开数据至 MySQL 中。将爬取的数据进行清洗和分析。将分析好的数据进行维度建模存入 MySQL 中。用 Flask 同 ECharts 将数据进行可视化展现。
- **项目重点收获**：熟悉了 Scrapy 框架的使用，在 Linux 环境下进行作业，根据指标进行维度建模。

- **项目名称**：阿里巴巴达摩院扫地项目
- **项目时间**：2022.06 - 2022.07
- **项目描述**：教别人如何扫地，如何扫好地
- **项目技术栈**：Hadoop、Sqoop、Python、Scrapy、Spark、Hive、MySQL、Flask、ECharts
- **指责描述**：进行 Hadoop 平台搭建，利用 Scrapy 爬取 QTA 酒店公开数据至 MySQL 中。将爬取的数据进行清洗和分析。将分析好的数据进行维度建模存入 MySQL 中。用 Flask 同 ECharts 将数据进行可视化展现。
- **项目重点收获**：熟悉了 Scrapy 框架的使用，在 Linux 环境下进行作业，根据指标进行维度建模。
`

export default {
  name: '互联网IT',
  primaryColor: '#333',
  primaryBackground: '#333',
  img: 'https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9596edaa90154e8ea291f5cf71798ae9~tplv-k3u1fbpfcp-watermark.image?',
  content
}
